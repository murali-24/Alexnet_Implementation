{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9631fc3",
   "metadata": {},
   "source": [
    "<h2> Setting seed </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "#This ensures that the model is deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5cd6d",
   "metadata": {},
   "source": [
    "<h2> Image Transformations </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ac479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet stats\n",
    "\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "    # transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std),\n",
    "])\n",
    "\n",
    "#validation and test transformation will be same\n",
    "val_transforms =transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46173c",
   "metadata": {},
   "source": [
    "<h2> Dataset Creation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"../../datasets/tiny-imagenet-200/train\"\n",
    "VAL_DIR = \"../../datasets/tiny-imagenet-200/val\"\n",
    "'''\n",
    "    Here, the training and validation sets are taken from the original Tiny imagenet dataset. But since the \n",
    "    test labels are not available for original tiny imagenet, the model is evaluated tiny imagenet cleaned\n",
    "    version from huggingface. This allows us to train the model using the full original tiny image net data, \n",
    "    while also ensuring the model is tested.\n",
    "'''\n",
    "train_dataset = ImageFolder(root=TRAIN_DIR, transform=train_transforms)\n",
    "val_dataset = ImageFolder(root=VAL_DIR, transform=val_transforms)\n",
    "# test_dataset = ImageFolder(root=TEST_DIR, transform=val_transforms)\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c71499",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Tried different number of workers, above 4 workers there isn't much improvement in the data transfer. The \n",
    "cost overhead of setting up parallel connections is greater when more than 4 workers are used.\n",
    "'''\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706e08f",
   "metadata": {},
   "source": [
    "<h2> Dataset Testing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491cda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(f\"Image shape: {images.shape}\") \n",
    "    print(f\"Label: {labels.shape}\")\n",
    "    break\n",
    "\n",
    "#Verifying whether the dataloader is working correctly\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9bfaa",
   "metadata": {},
   "source": [
    "<h2> Alexnet Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925eb44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(nn.Module):\n",
    "    \"\"\"\n",
    "        The original alexnet architecture is implement in the below code. Every parameter image size, \n",
    "        layers, kernel size, stride, padding etc.., are exactly same as in the paper, Except for \n",
    "            1. No model splitting between GPUs\n",
    "            2. Final fully connected layer has 200 outputs instead of 1000 outputs in original paper,\n",
    "            to match the number of classes in tiny imagenet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11,stride=4,padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5,stride=1,padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=384,out_channels=384,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        feature_extractor_layers = [self.conv1, self.relu, self.maxpool, self.conv2, self.relu,\n",
    "                                    self.maxpool, self.conv3, self.relu, self.conv4, self.relu,\n",
    "                                    self.conv5, self.relu, self.maxpool]\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*feature_extractor_layers)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=9216, out_features=4096)\n",
    "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
    "        self.fc3 = nn.Linear(in_features=4096, out_features=200)\n",
    "\n",
    "        classifier_layers = [self.dropout, self.fc1, self.relu, self.dropout, self.fc2,\n",
    "                             self.relu, self.fc3]\n",
    "        self.classifier = nn.Sequential(*classifier_layers)\n",
    "\n",
    "\n",
    "    def forward(self,images):\n",
    "        out = self.feature_extractor(images)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847e06f",
   "metadata": {},
   "source": [
    "<h2> Model Initializaton </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57492f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_of_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "model = Alexnet().to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #type: ignore\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3,factor=0.1)\n",
    "#The learning rate scheduler decrease learning rate by factor of 10 if validation accuracy\n",
    "#doesn't improve for 3 epochs\n",
    "checkpoint_path = r\"../checkpoints/current_model.pth\" #stores the current model\n",
    "best_model_path = r\"../checkpoints/best_model.pth\" #stores the best model upto date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610fae38",
   "metadata": {},
   "source": [
    "<h2> Training Loop </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6e081",
   "metadata": {},
   "source": [
    "<h3>&nbsp;&nbsp;&nbsp;&nbsp; 1. Displaying the train/val report for one epoch </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average training loss and accuracy for each epoch is printed for display\n",
    "def display_one_epoch_summary(epoch,num_of_epochs, train_loss,train_accuracy, val_loss, val_accuracy):\n",
    "    print(f\"\\nEpoch [{epoch}/{num_of_epochs}] Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d4937",
   "metadata": {},
   "source": [
    "<h3>&nbsp;&nbsp;&nbsp;&nbsp; 2. Checkpoint Saving </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler, history, best_val_loss, patience_counter, checkpoint_path):\n",
    "    \"\"\" \n",
    "        The model is stored at regular intervals to resume training if interrupted. Two different\n",
    "        models are stored:\n",
    "            1. Current/Latest version of model\n",
    "            2. The model is lowest validation loss\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    #Model must not update the weights while saving to avoid that we use eval mode\n",
    "    torch.save({\n",
    "        'epoch': epoch, \n",
    "        'model_state_dict': model.state_dict(), #stores model's learnt weights, biases\n",
    "        'optimizer_state_dict': optimizer.state_dict(), #stores momentum, weight decay info\n",
    "        'scheduler_state_dict': scheduler.state_dict(), #stores learning rate history\n",
    "        'history':history,  #the train/val loss and accuracy history is stored\n",
    "        'best_val_loss':best_val_loss, #the best validation loss is stored to be used for early stopping\n",
    "        'patience_counter':patience_counter #patience counter for early stopping is needed\n",
    "    }, checkpoint_path)\n",
    "\n",
    "def load_checkpoint(device, model, optimizer, scheduler, checkpoint_path):\n",
    "    \"\"\" \n",
    "        Loads the saved model. try-except block is added \n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üîÅ Resuming from checkpoint...\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        history = checkpoint['history']\n",
    "        patience_counter = checkpoint['patience_counter']\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "\n",
    "        print(f\"‚úÖ Loaded checkpoint from epoch {checkpoint['epoch']} with val loss {best_val_loss:.4f}\")\n",
    "        return start_epoch,history,patience_counter,best_val_loss\n",
    "    \n",
    "    except (RuntimeError, EOFError) as e:\n",
    "        print(f\"‚ùå Error loading checkpoint: {e}\")\n",
    "        print(\"Starting training from scratch.\")\n",
    "        return 1, {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}, 0, float('inf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd82ae25",
   "metadata": {},
   "source": [
    "<h3> &nbsp;&nbsp;&nbsp;&nbsp; 3. Tensorboard visualization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    tensorboard setup is added to visualize training/validation loss and accuracy curve, learning rate curve\n",
    "    from learning rate schedule and gradient histograms from selective layers (conv1, conv5, fc1, fc3) are\n",
    "    also visualized to observe vanishing and exploding gradients.\n",
    "\"\"\"\n",
    "\n",
    "def setup_tensorboard(log_dir=\"../logs/experiment_1\"):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    writer = SummaryWriter(log_dir=log_dir) #Writer to write events in tensor board\n",
    "    return writer\n",
    "\n",
    "def log_train_val_curve(writer, epoch, train_loss, train_accuracy, val_loss, val_accuracy):\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Train\", train_accuracy, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Val\", val_accuracy, epoch)\n",
    "\n",
    "def log_learning_rate(writer, epoch, optimizer): #learning rate of optimizer is logged.\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        writer.add_scalar(f\"LR/group_{i}\", param_group['lr'], epoch)\n",
    "\n",
    "def log_selected_gradients(model, writer, epoch, layer_keywords=(\"conv1\", \"conv5\", \"fc1\", \"fc3\")):\n",
    "    \"\"\"\n",
    "    Logs gradient histograms and gradient norms of selected layers to TensorBoard.\n",
    "    Helps diagnose vanishing or exploding gradients during training.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model being trained.\n",
    "        writer (SummaryWriter): TensorBoard writer.\n",
    "        epoch (int): Current epoch number.\n",
    "        layer_keywords (tuple): Substrings to match parameter names (e.g., layer names).\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None and any(key in name for key in layer_keywords):\n",
    "            try:\n",
    "                grad = param.grad.detach().view(-1)\n",
    "                grad_norm = grad.norm().item()\n",
    "\n",
    "                # Log histogram of gradients\n",
    "                writer.add_histogram(f\"Gradients/{name}\", grad, epoch)\n",
    "                # Log L2 norm of gradients as scalar\n",
    "                writer.add_scalar(f\"GradientsNorm/{name}\", grad_norm, epoch)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Failed to log gradient for {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535653e",
   "metadata": {},
   "source": [
    "<h3> &nbsp;&nbsp;&nbsp;&nbsp; 4. Training one epoch</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard training loop for a single epoch is given\n",
    "def train_one_epoch(device, epoch, num_of_epochs, train_loader, model, criterion, optimizer, clip_value):\n",
    "    train_loss = 0\n",
    "    train_correct = 0 #needed for accuracy calculation\n",
    "    train_total = 0 #total number of images given as input \n",
    "    \n",
    "    model.train() #The model is run in training mode\n",
    "    for batch_idx, (images, labels) in tqdm(enumerate(train_loader),\n",
    "                                                total=len(train_loader), desc=f\"Epoch {epoch} [Train]\"):\n",
    "        #move to GPU\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #1. Make predictions\n",
    "        predictions = model(images)\n",
    "        #2. Compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        #3. clear previous gradients if any\n",
    "        optimizer.zero_grad()\n",
    "        #4. Compute gradients from loss using backpropagation\n",
    "        loss.backward()\n",
    "        #5. Clip gradient if they exceed clip value threshold -> avoids exploding gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        #6. Update weights/biases based on gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        #update loss and predictions to calculate loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (predictions.argmax(1) == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "        \n",
    "        #print progress\n",
    "        if (batch_idx ) % 10 == 0:\n",
    "            tqdm.write(f\"[Train] Epoch [{epoch}/{num_of_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "        #tqdm is used to get a nice progress bar\n",
    "    \n",
    "    #average loss in an epoch     \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "    return avg_train_loss, train_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b793f4",
   "metadata": {},
   "source": [
    "<h3> &nbsp;&nbsp;&nbsp;&nbsp; 5. Validation for one epoch</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to evaluating (validation) for one epoch\n",
    "\n",
    "def evaluate_one_epoch(device, epoch, num_of_epochs, val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad(): #makes sure gradient doesn't change during validation\n",
    "        for batch_idx, (images, labels) in tqdm(enumerate(val_loader),\n",
    "                                                    total=len(val_loader), desc=f\"Epoch {epoch} [VAL]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(images)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_correct += (predictions.argmax(1) == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            if (batch_idx ) % 10 == 0:\n",
    "                tqdm.write(f\"[Val] Epoch [{epoch}/{num_of_epochs}], Step [{batch_idx+1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    #average loss in an epoch     \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    return avg_val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59421fca",
   "metadata": {},
   "source": [
    "<h3> &nbsp;&nbsp;&nbsp;&nbsp; 6. Main Training Loop</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader,val_loader, criterion, optimizer,scheduler,num_of_epochs,\n",
    "                 device, clip_value=10,checkpoint_path=r\"../checkpoints/current_model.pth\",\n",
    "                  best_model_path=r\"../checkpoints/best_model.pth\", resume=False ):\n",
    "    \n",
    "    start_epoch = 1 #It is needed if model is resumed after training for some time. (then it will not be 1)\n",
    "    best_val_loss = float('inf') #used for early stopping\n",
    "\n",
    "    #stores train/val loss and accuracy for plotting in tensorboard\n",
    "    history = {\n",
    "        \"train_loss\": [], \"val_loss\": [],\n",
    "        \"train_acc\": [], \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    #parameters for early stopping\n",
    "    early_stop_patience = 8\n",
    "    patience_counter = 0\n",
    "\n",
    "    writer = setup_tensorboard()\n",
    "# Resume from checkpoint if available\n",
    "    if resume and os.path.exists(checkpoint_path):\n",
    "        start_epoch,history, patience_counter,best_val_loss = load_checkpoint(device, model, optimizer, scheduler, checkpoint_path)\n",
    "\n",
    "    for epoch in range(start_epoch, num_of_epochs+1):\n",
    "\n",
    "        #train and validate data \n",
    "        avg_train_loss, train_accuracy = train_one_epoch(device, epoch, num_of_epochs, train_loader, model, criterion, optimizer, clip_value)\n",
    "        avg_val_loss, val_accuracy = evaluate_one_epoch(device, epoch, num_of_epochs, val_loader, model, criterion)\n",
    "        \n",
    "        #update LR using LR scheduler using validation loss\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        #stores train/val loss and accuracy for plotting and logging \n",
    "        history[\"train_loss\"].append(avg_train_loss)\n",
    "        history[\"val_loss\"].append(avg_val_loss)\n",
    "        history[\"train_acc\"].append(train_accuracy)\n",
    "        history[\"val_acc\"].append(val_accuracy)\n",
    "\n",
    "        #Saves the current model\n",
    "        save_checkpoint(epoch, model, optimizer, scheduler, history, best_val_loss, patience_counter, checkpoint_path)\n",
    "\n",
    "        #Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            #if val loss doesn't improve till patience counter exceeds a certain value,\n",
    "            #the training is stopped\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0 \n",
    "            #best model is saved\n",
    "            save_checkpoint(epoch, model, optimizer, scheduler, history, best_val_loss, patience_counter, best_model_path)\n",
    "            print(\"üåü New best model saved.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > early_stop_patience:\n",
    "                print(f\"‚èπ Early stopping at epoch {epoch}. No improvement for {early_stop_patience} epochs.\")\n",
    "                break\n",
    "        \n",
    "        #tensorboard visualization for train/val loss and accuracy\n",
    "        log_train_val_curve(writer, epoch, avg_train_loss, train_accuracy, avg_val_loss, val_accuracy)\n",
    "        #tensorboard visualization for learning rate\n",
    "        log_learning_rate(writer, epoch, optimizer)\n",
    "        if epoch%10==0:\n",
    "            #tensorboard visualization for gradients\n",
    "            log_selected_gradients(model, writer, epoch)\n",
    "        #prints epoch summary\n",
    "        display_one_epoch_summary(epoch, num_of_epochs, avg_train_loss, train_accuracy,avg_val_loss, val_accuracy)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d19a72",
   "metadata": {},
   "source": [
    "<h2> Train Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90effe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(model, train_loader,val_loader, criterion, optimizer,scheduler,num_of_epochs,\n",
    "                 device, clip_value=10,checkpoint_path=checkpoint_path,best_model_path=best_model_path, resume=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be7396",
   "metadata": {},
   "source": [
    "<h2> Log hyperparameters and Final Metrics </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_experiment(log_file, hyperparams, metrics):\n",
    "    \"\"\"\n",
    "        Stores the details, hyperparametrics and final metrics of training for future \n",
    "        reference and optimization purposes. \n",
    "    \"\"\"\n",
    "    log_entry = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"hyperparameters\": hyperparams,\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, \"r\") as f:\n",
    "            logs = json.load(f)\n",
    "    else:\n",
    "        logs = []\n",
    "\n",
    "    logs.append(log_entry)\n",
    "\n",
    "    with open(log_file, \"w\") as f:\n",
    "        json.dump(logs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce484f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_log_file = \"../logs/experiment_log.json\"\n",
    "csv_log_file = \"../logs/experiment_log.csv\"\n",
    "\n",
    "hyperparams = {\n",
    "    \"model\": \"AlexNet\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": num_of_epochs,\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"clip_value\": 10,\n",
    "    \"early_stop_patience\": 8,\n",
    "    \"transform\": \"Resize(256)->Crop->Flip->Norm\",\n",
    "    \"Weight Initialization\": None,\n",
    "    \"seed\":42,\n",
    "    \n",
    "}\n",
    "\n",
    "final_metrics = {\n",
    "    \"final_train_loss\": history[\"train_loss\"][-1],\n",
    "    \"final_val_loss\": history[\"val_loss\"][-1],\n",
    "    \"final_train_acc\": history[\"train_acc\"][-1],\n",
    "    \"final_val_acc\": history[\"val_acc\"][-1],\n",
    "    \"best_val_loss\": min(history[\"val_loss\"]),\n",
    "    \"best_val_acc\": max(history[\"val_acc\"]),\n",
    "\n",
    "}\n",
    "\n",
    "log_experiment(json_log_file, hyperparams, final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618ad8e",
   "metadata": {},
   "source": [
    "<h2> Convert JSON log file to CSV </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f90153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_csv(json_path, csv_path):\n",
    "    \"\"\"\n",
    "        Converts json hyperparameter and metric log files into csv for\n",
    "        tabular representation and use with libraries such as pandas.\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        logs = json.load(f)\n",
    "\n",
    "    # Flatten entries (combine hyperparameters and metrics)\n",
    "    flattened_logs = []\n",
    "    for entry in logs:\n",
    "        flat = {\n",
    "            \"timestamp\": entry[\"timestamp\"],\n",
    "            **entry[\"hyperparameters\"],\n",
    "            **entry[\"metrics\"]\n",
    "        }\n",
    "        flattened_logs.append(flat)\n",
    "\n",
    "    df = pd.DataFrame(flattened_logs)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"‚úÖ Log converted to CSV: {csv_path}\")\n",
    "\n",
    "convert_json_to_csv(json_log_file, csv_log_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
